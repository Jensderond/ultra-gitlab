## Codebase Patterns
- Sync engine in src-tauri/src/services/sync_engine.rs — runs background tokio task, processes SyncCommand enum (TriggerSync, UpdateConfig, Stop) via mpsc channel
- SyncHandle stored as Tauri managed state, has send() method to send commands to the sync engine
- Approval commands in src-tauri/src/commands/approval.rs — approve_mr and unapprove_mr enqueue actions via sync_queue then return immediately
- Sync queue in src-tauri/src/services/sync_queue.rs — enqueue_action(), get_pending_actions(), process via sync_processor
- Sync processor in src-tauri/src/services/sync_processor.rs — process_action() handles individual action execution against GitLab API
- ActionType enum includes Approve, Comment, Reply, Resolve, Unresolve
- Approval commands accept both pool: State<DbPool> and sync_handle: State<SyncHandle> — Tauri auto-injects managed state by type
- Command registration: src-tauri/src/commands/mod.rs (re-exports) and src-tauri/src/lib.rs (generate_handler!)
- GitLab client: approve_merge_request() and unapprove_merge_request() POST endpoints in gitlab_client.rs
- SyncCommand now has FlushApprovals variant; SyncHandle has flush_approvals() convenience method
- flush_approval_actions() on SyncEngine filters pending actions by ActionType::Approve, looks up instance per MR, creates client, and processes each action
- sync_queue::get_pending_actions_by_type() filters at DB level by ActionType; flush_approval_actions uses it instead of in-memory filtering

---

## 2026-02-06 - US-001
- What was implemented: Added `FlushApprovals` variant to `SyncCommand` enum, handled it in the sync engine background loop, added `flush_approvals()` convenience method on `SyncHandle`, and added `flush_approval_actions()` on `SyncEngine` that filters pending actions to only approval types and processes them individually.
- Files changed: src-tauri/src/services/sync_engine.rs
- **Learnings for future iterations:**
  - The flush_approval_actions method needs to look up the instance_id from the merge_requests table for each action, since actions don't store instance_id directly
  - Each approval action may belong to a different GitLab instance, so the method creates a client per action (could be optimized to cache clients per instance if needed)
  - The existing `process_action` from sync_processor handles all status transitions (mark_syncing, mark_synced, mark_failed) so the flush just needs to call it
  - ActionType::Approve covers both approve and unapprove (the payload distinguishes them via the "action" field)
---

## 2026-02-06 - US-002
- What was implemented: Added `get_pending_actions_by_type()` to `sync_queue.rs` that accepts an `ActionType` filter and queries `sync_queue WHERE status = 'pending' AND action_type = ?`. Updated `flush_approval_actions()` in `sync_engine.rs` to use this new DB-level filtered query instead of fetching all pending actions and filtering in-memory. Added a comprehensive test covering filtering by Approve (1 match), Comment (2 matches), and Resolve (0 matches / empty vec).
- Files changed: src-tauri/src/services/sync_queue.rs, src-tauri/src/services/sync_engine.rs
- **Learnings for future iterations:**
  - The function follows the same pattern as `get_pending_actions` — uses `sqlx::query_as::<_, SyncAction>` and returns `Result<Vec<SyncAction>, AppError>`
  - ActionType implements Display (returns lowercase string like "approve"), which is used with `.bind(action_type.to_string())` for the SQL parameter
  - DB-level filtering is preferable to in-memory filtering for efficiency and clarity
---

## 2026-02-06 - US-003
- What was implemented: Modified `approve_mr` command to accept `SyncHandle` as managed state in addition to `DbPool`. After successfully enqueuing the approve action, the command sends a `FlushApprovals` signal via `sync_handle.flush_approvals()`. The signal is fire-and-forget: if sending fails (e.g., channel closed), the error is logged with `eprintln!` but not propagated to the frontend.
- Files changed: src-tauri/src/commands/approval.rs
- **Learnings for future iterations:**
  - Tauri auto-injects managed state by type — just add `sync_handle: State<'_, SyncHandle>` as a parameter and it works, no changes to lib.rs generate_handler needed
  - The `flush_approvals()` method is async, so we can await it inline and handle the error with a simple `if let Err`
  - No changes needed to commands/mod.rs or lib.rs — the command signature change is transparent to Tauri's handler registration
---

## 2026-02-06 - US-004
- What was implemented: Modified `unapprove_mr` command to accept `SyncHandle` as managed state (mirroring `approve_mr`). After enqueuing the unapprove action, the command sends a `FlushApprovals` signal via `sync_handle.flush_approvals()`. The signal is fire-and-forget with error logging using `[unapproval]` prefix.
- Files changed: src-tauri/src/commands/approval.rs
- **Learnings for future iterations:**
  - This was a direct mirror of US-003 — same pattern of adding `sync_handle: State<'_, SyncHandle>` and the fire-and-forget flush block
  - No changes needed to lib.rs or mod.rs for the signature update (confirmed pattern from US-003)
  - The unapprove action uses ActionType::Approve with "action": "unapprove" in the payload — the flush handles both approve and unapprove since they share the same ActionType
---

## 2026-02-06 - US-005
- What was implemented: Verification-only story — no code changes needed. All acceptance criteria were already satisfied by the existing implementation from US-001 through US-004.
- Files changed: None (only prd.json updated)
- **Verification details:**
  - `process_action()` in sync_processor.rs handles failures via `mark_failed()` which resets status to "pending" if retry count < max, or "failed" if max retries reached — actions stay in queue for retry
  - `flush_approval_actions()` in sync_engine.rs iterates all approval actions and continues past failures — no crash/block
  - Failed actions with status "pending" are picked up by the next regular sync cycle via `push_pending_actions()` → `get_pending_actions()`
  - No frontend events or notifications are emitted during flush — only `eprintln!` logging
- **Learnings for future iterations:**
  - The existing `process_action` + `mark_failed` retry logic was designed to be reusable — it handles both regular sync and flush scenarios without modification
  - When a story's acceptance criteria are already met by prior work, treat it as a verification story: confirm each criterion, document findings, and mark as passing
---

