{
  "project": "Ultra GitLab",
  "branchName": "ralph/critical-bug-fixes",
  "description": "Critical Bug Fixes - Fix data loss, incorrect behavior, and security issues found during bug hunt",
  "userStories": [
    {
      "id": "US-001",
      "title": "Fix generate_local_id collisions within same second",
      "description": "As a user, I want to rapidly add comments and replies without losing any, so that my review workflow isn't interrupted by silent failures.",
      "acceptanceCriteria": [
        "Change generate_local_id() in src-tauri/src/commands/comments.rs to use millisecond-granularity timestamp combined with an atomic counter (AtomicI64) to guarantee uniqueness",
        "The function must still return negative i64 values (existing negative IDs in DB must remain valid)",
        "Add #[cfg(test)] mod tests in the same file with a test that calls generate_local_id() 100 times in a tight loop and asserts all values are unique (use a HashSet)",
        "Add a test that calls generate_local_id() from 2 spawned threads (10 calls each) and asserts no duplicates across threads",
        "cargo check passes"
      ],
      "priority": 1,
      "passes": true,
      "notes": ""
    },
    {
      "id": "US-002",
      "title": "Fix retry_failed_actions using wrong instance credentials",
      "description": "As a user with multiple GitLab instances, I want the Retry failed actions feature to use the correct credentials for each action, so that retries don't fail with 401/404 errors.",
      "acceptanceCriteria": [
        "In retry_failed_actions in src-tauri/src/commands/sync.rs, remove the ORDER BY id LIMIT 1 query that picks a single instance",
        "Instead, query each failed action's instance by joining sync_queue.mr_id to merge_requests.instance_id to gitlab_instances (SELECT gi.id, gi.url, gi.token FROM sync_queue sq JOIN merge_requests mr ON sq.mr_id = mr.id JOIN gitlab_instances gi ON mr.instance_id = gi.id WHERE sq.status = 'failed')",
        "Group actions by instance_id and create one GitLabClient per instance",
        "Process each group's actions with its own client",
        "If an action's instance is not found (deleted instance), mark the action as permanently failed instead of silently skipping",
        "cargo check passes"
      ],
      "priority": 2,
      "passes": true,
      "notes": ""
    },
    {
      "id": "US-003",
      "title": "Preserve GitLab error body in handle_response for 403 status",
      "description": "As a user, I want stale sync actions to be automatically discarded based on GitLab's actual error message, so they don't retry forever.",
      "acceptanceCriteria": [
        "In handle_response in src-tauri/src/services/gitlab_client.rs, change the 403 match arm from (StatusCode::FORBIDDEN, _) => \"Access denied\".to_string() to (StatusCode::FORBIDDEN, Some(msg)) => msg.clone() with fallback (StatusCode::FORBIDDEN, None) => \"Access denied\".to_string()",
        "Add a unit test: construct a body_message of Some(\"Cannot approve: MR is already merged\".to_string()) and verify the resulting error message contains \"merged\" not \"Access denied\"",
        "Add a unit test: construct body_message of None for 403 and verify fallback to \"Access denied\"",
        "cargo check passes"
      ],
      "priority": 3,
      "passes": true,
      "notes": ""
    },
    {
      "id": "US-004",
      "title": "Fix post_empty, resolve_discussion, and delete_note to read error response body",
      "description": "As a user, I want all GitLab API error responses to preserve their actual error message, so that conflict detection works for approvals, resolves, and deletions.",
      "acceptanceCriteria": [
        "Extract a shared async helper method error_from_response(&self, response: reqwest::Response, endpoint: &str) -> AppError in gitlab_client.rs that reads response.text(), attempts to parse as JSON to extract a message field, and returns AppError::gitlab_api_full with the parsed message (or a formatted fallback like 'Request failed (STATUS)')",
        "Update post_empty to use error_from_response instead of returning generic 'Request failed'",
        "Update resolve_discussion to use error_from_response instead of returning generic 'Failed to resolve discussion'",
        "Update delete_note to use error_from_response instead of returning generic 'Failed to delete note'",
        "cargo check passes"
      ],
      "priority": 4,
      "passes": true,
      "notes": ""
    },
    {
      "id": "US-005",
      "title": "Fix purge_closed_mrs comparing wrong ID types",
      "description": "As a user, I want my open MRs to never be incorrectly purged during background sync, so that I don't lose cached diffs, comments, and file content.",
      "acceptanceCriteria": [
        "In sync_instance in src-tauri/src/services/sync_engine.rs, collect the local_mr_id returned from each sync_mr call into a Vec<i64>",
        "Pass this collected Vec to purge_closed_mrs instead of re-deriving IDs from the raw GitLab MR list",
        "Update purge_closed_mrs signature to accept the local DB IDs directly instead of extracting mr.id from GitLabMergeRequest objects",
        "The NOT IN clause in purge_closed_mrs must use these local DB IDs",
        "cargo check passes"
      ],
      "priority": 5,
      "passes": true,
      "notes": ""
    },
    {
      "id": "US-006",
      "title": "Recover actions stuck in syncing state after crash",
      "description": "As a user, I want actions that were mid-flight when the app crashed to be automatically recovered on next launch, so that my comments and approvals aren't permanently lost.",
      "acceptanceCriteria": [
        "Add a recover_stale_syncing_actions async function in src-tauri/src/services/sync_engine.rs (or sync_queue.rs) that runs UPDATE sync_queue SET status = 'pending' WHERE status = 'syncing'",
        "Call this function during sync engine initialization, before the first sync cycle begins (in start_sync or the SyncEngine constructor/init method)",
        "Log the number of recovered actions if any were found (e.g., eprintln or log::info)",
        "Add a unit test: insert 3 actions (one pending, one syncing, one failed) into an in-memory DB, call the recovery function, verify only the syncing one is reset to pending",
        "cargo check passes"
      ],
      "priority": 6,
      "passes": true,
      "notes": ""
    },
    {
      "id": "US-007",
      "title": "Secure companion QR code endpoint",
      "description": "As a user, I want the companion server PIN to not be exposed to unauthenticated LAN devices, so that unauthorized devices can't bypass authentication.",
      "acceptanceCriteria": [
        "Remove or protect the GET /api/auth/qr endpoint in src-tauri/src/services/companion_auth.rs so that it no longer serves the PIN to unauthenticated requests",
        "Add a new Tauri command get_companion_qr_code in the appropriate commands file that generates the QR code SVG string (move the QR generation logic from the HTTP handler to this command)",
        "Register the new command in commands/mod.rs and lib.rs generate_handler!",
        "The frontend companion pairing UI should call invoke('get_companion_qr_code') instead of fetching from the HTTP endpoint",
        "cargo check passes"
      ],
      "priority": 7,
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-008",
      "title": "Fix companion auth rate limit TOCTOU bypass",
      "description": "As a user, I want the companion server rate limiting to actually enforce attempt limits, so that brute-force PIN attacks are prevented.",
      "acceptanceCriteria": [
        "Combine is_rate_limited and record_failed_attempt in src-tauri/src/services/companion_auth.rs into a single pub async fn check_and_record_attempt(ip: IpAddr) -> bool that acquires one write lock, checks the count, records the attempt, and returns true if rate limited",
        "Update verify_pin_handler to call the new combined function instead of the separate is_rate_limited and record_failed_attempt",
        "After pruning expired entries for an IP, remove the IP key from the HashMap if the vec is empty (fixes memory leak)",
        "Add a unit test: call check_and_record_attempt MAX_ATTEMPTS times for the same IP, verify the last call returns true (rate limited)",
        "Add a unit test: after the rate limit window expires, verify the IP entry is cleaned up from the HashMap",
        "cargo check passes"
      ],
      "priority": 8,
      "passes": false,
      "notes": ""
    }
  ]
}
